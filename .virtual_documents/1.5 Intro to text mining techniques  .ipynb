


from textblob import TextBlob 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import nltk
import re
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from collections import Counter
sns.set()





myfile = open('alice_in_wonderland.txt', encoding='utf-8') 


# Import txt file

with open('alice_in_wonderland.txt', 'r', errors='ignore') as file:
    data = file.read().replace('\n', '')


# Sentence tokenization 

from nltk.tokenize import sent_tokenize
tokenized_sent = sent_tokenize(data)
print(tokenized_sent)


# Word tokenization

from nltk.tokenize import word_tokenize
tokenized_word = word_tokenize(data)
print(tokenized_word)


# Create frequency distribution

from nltk.probability import FreqDist
dist_words = FreqDist(tokenized_word)
print(dist_words)


dist_words.most_common(10)


# Frequency Distribution Plot

plt.figure(figsize=(8, 3))
dist_words.plot(10,cumulative = False)
plt.show()





# Defining stopwords

from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))
print(stop_words)


# Removing stopwords in sentences

# filtered_sent = []
# for word in tokenized_sent:
#     if word not in stop_words:
#         filtered_sent.append(word)
# print("Tokenized Sentence:", tokenized_sent)
# print("Filterd Sentence:", filtered_sent)


# Removing stopwords in words

filtered_words = [] # creates an empty list
for word in tokenized_word:
    if word not in stop_words:
        filtered_words.append(word)


filtered_words


# Create a new FreqDist for filtered_words

dist_words_filter = FreqDist(filtered_words)
print(dist_words_filter)


# Frequency Distribution Plot

plt.figure(figsize=(8, 3))
dist_words_filter.plot(10, cumulative = False)
plt.show()


dist_words_filter


# Substitute all punctuations marks with a space 

sans_punc = re.sub("[^a-zA-Z]",  # Search for all non-letters
                          " ",          # Replace all non-letters with spaces
                          str(filtered_words))


sans_punc


# Word tokenization

tokenized_word_2 = word_tokenize(sans_punc)
print(tokenized_word_2)


# Create a new FreqDist

dist_words_filter_2 = FreqDist(tokenized_word_2)


# Frequency Distribution Plot

plt.figure(figsize=(8, 3))
dist_words_filter_2.plot(30, cumulative = False)
plt.show()


dist_words_filter_2.most_common(20)





new_stopwords = ["And", "Then", 'n', 't', 's', 'The']


filtered = []
for word in tokenized_word_2:
    if word not in new_stopwords:
        filtered.append(word)


%%time
text = TextBlob(str(filtered))


text


tags_list = text.tags


tags_list


df_text = pd.DataFrame(tags_list)
df_text.columns = ['Words', "Word type"]


df_text.head()


df_t = df_text.groupby('Word type').count().reset_index()


df_t.head()


top20 = df_t.nlargest(20, 'Words')


plt.figure(figsize = (10, 5))
with sns.dark_palette("xkcd:blue", 20):
    sns.barplot(x = "Words", y = "Word type",
    saturation = 0.9, data = top20).set_title("Alice in Wonderland - top 20 word types used")


# def word_analysis(word_type):
#     filtered = [row for row in my_list if str(word_type) in row[1]]
#     print("filtered for " + word_type)
#     df = pd.DataFrame(filtered)
#     df.columns = ["Word", "Occurences"]
#     x=df.groupby('Word').count().reset_index()
#     y=x.sort_values(by=['Occurences'], ascending=False)
#     top10=y.nlargest(10, 'Occurences')
#     plt.figure(figsize=(10, 5))
#     sns.barplot(x="Word", y="Occurences", palette="rocket", saturation=0.9, data=top10).set_title("Lord of the rings - most frequently used "+ word_type +" type word")





df = df_text[(df_text['Word type'] == "NN") | (df_text['Word type'] == "NNS") | (df_text['Word type'] == "NNP")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurences'], ascending=False)
top10 = y.nlargest(10, 'Occurences')


top10


plt.figure(figsize=(10, 5))
with sns.dark_palette("xkcd:blue", 10):
    sns.barplot(x="Word", y="Occurences",
    saturation=0.9, data = top10).set_title("Alice in Wonderland - most frequently used nouns")





df = df_text[(df_text['Word type'] == "VB")  | (df_text['Word type'] == "VBD")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurences'], ascending=False)
top10 = y.nlargest(10, 'Occurences')


top10


plt.figure(figsize = (10, 5))
with sns.dark_palette("xkcd:blue", 10):
    sns.barplot(x = "Word", y = "Occurences",
    saturation = 0.9, data = top10).set_title("Alice in Wonderland - most frequently used verbs")





df = df_text[df_text['Word type'] == "JJ"]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by=['Occurences'], ascending=False)
top10 = y.nlargest(10, 'Occurences')


plt.figure(figsize=(10, 5))
with sns.dark_palette("xkcd:blue", 10):
    sns.barplot(x="Word", y="Occurences",
    saturation=0.9, data=top10).set_title("Alice in Wonderland - most frequently used adjectives")





listToStr = ' '.join([str(elem) for elem in filtered])
 
print(listToStr)


# Create a count for the main characters

all_counts = Counter(re.sub(r'\W+', ' ', listToStr).split())


all_counts


chars = pd.read_csv("Alice_characters.csv", index_col = 0)


chars.head()


# Replace names with aliases

chars['character'] = chars['character'].replace('Bill the Lizard','Bill')
chars['character'] = chars['character'].replace('The Queen of Hearts','Queen')
chars['character'] = chars['character'].replace('The King of Hearts','King')
chars['character'] = chars['character'].replace('The Knave of Hearts','Knave')


chars


chars['character_alias'] = chars['character'].apply(lambda x: x.rsplit(' ', 1)[-1])


chars


char_list = chars['character_alias'].to_list()


dict_of_counts = {d : all_counts[d] for d in char_list}


dict_of_counts


# Search for the names from the list in the dictionary

dct = {v:[k] for v,k in dict_of_counts.items()}  
df = pd.DataFrame(dct)


df


df = df.transpose().reset_index()


df.dtypes


df


df.rename(columns = {"index":"Character", 0:"Times mentioned"}, inplace = True)


df


df.shape


plt.figure(figsize=(10, 5))
with sns.dark_palette("#79C", 27):
    sns.barplot(x = "Times mentioned", y = "Character",
    saturation=0.9, data = df.sort_values("Times mentioned", ascending = False)).set_title("Alice in Wonderland - most frequently mentioned characters")


chars.to_csv("characters_alice.csv")





text_sent = TextBlob(str(filtered))


print(text_sent.sentiment)
